#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# pylint: disable=C,R,locally-disabled

import re
from bs4 import BeautifulSoup
from odtfile import OdtFile
from pathlib import Path
from unidecode import unidecode
import pickle


def correct_tree(odt_content, style_name, tag_name):
    """Corrects content.xml document tree.

    Replaces the autogenerated style name with the name of desired style in
    desired tag (Ex.: 'text:p', 'text:h'). This is needed for correct
    retrieving of journal titles to global dictionary.

    Args: odt_content: an instance of BeautifulSoup class containing an
    XML-tree of content.xml file;
    style_name: a name of desired attribute. Example "СтатьяНазваниеРус";
    tag_name: a name of desired tag. Example "text:h".

    Returns: None. Changes by reference a global dictionary of journal
    information.

    Raises: TODO
    """

    nodes_list = odt_content.find_all('style:style',
                                      {'style:parent-style-name': style_name})
    list_of_node_number_styles = []

    for node in nodes_list:
        if node['style:name'] not in list_of_node_number_styles:
            list_of_node_number_styles.append(node['style:name'])

    for number_style in list_of_node_number_styles:
        nodes_list = odt_content.find_all(tag_name,
                                          {'text:style-name': number_style})
        for node in nodes_list:
            element = odt_content.find(
                tag_name, {'text:style-name': number_style})
            element['text:style-name'] = style_name


def clear_text(text):
    """Deletes spaces, doublespaces and other not needed symbols from string.

    Replaces the autogenerated style name with the name of desired style. This
    is needed for correct retrieving of journal titles.

    Args: text: A string to clear

    Returns: undoubled_text: cleaned string

    Raises: TODO

    """
    stripped_text = text.strip().rstrip('*')
    undoubled_text = re.sub('\s+', ' ', stripped_text)

    return undoubled_text


# def get_journal_pub_numbers(odt_content, journal_info):

#     correct_tree(odt_content, 'ТитулНомерВыпускаРус', 'text:p')

#     issue_tag = odt_content.find('text:p',
#                                  {'text:style-name': 'ТитулНомерВыпускаРус'})
#     issue_numbers_string = issue_tag.get_text()

#     regex = re.compile(r'^\D+(\d+)\D+(\d+)')  # Regex for extracting Volume
#     #  and Issue numbers
#     result = regex.match(issue_numbers_string)

#     print('Volume:', result[1])
#     print('Issue:', result[2])


def get_journal_through_issue_number(odt_content, journal_info):

    correct_tree(odt_content, 'ТитулВыходныеДанныеЖурналаРус', 'text:p')

    issue_tag = odt_content.find('text:p',
                                 {'text:style-name':
                                  'ТитулВыходныеДанныеЖурналаРус'})
    title_info_text = issue_tag.parent.parent.get_text()

    regex = re.compile(r'^.*\(сквозной\)\s?номер\s?(\d+)')

    result = regex.match(title_info_text)

    journal_info['JOURNAL'] = {'THROUGH_ISSUE_NUMBER': result[1]}


def get_journal_titles(odt_content, journal_info):
    """Gets English and Russian journal titles.

    Gets English and Russian titles from content.xml using BeautifulSoup.

    Args: odt_content: an instance of BeautifulSoup class containing an
    XML-tree of content.xml file
    journal_info: reference to global dictionary to add title information

    Returns: None. Changes by reference a global dictionary of journal
    information.

    Raises: TODO
    """
    journal_titles_with_tags = odt_content.find_all('svg:title')
    journal_titles = ({'JOURNAL_NAME_RU':
                       journal_titles_with_tags[0].get_text(),
                       'JOURNAL_NAME_EN':
                       journal_titles_with_tags[1].get_text()})

    if 'JOURNAL' not in journal_info:
        journal_info['JOURNAL'] = {}
    journal_info['JOURNAL'] = journal_titles


def get_article_names_from_title(content, journal_info):
    """Gets English and Russian article names.

    Gets English and Russian article names from content.xml
    using BeautifulSoup.

    Args: odt_content: an instance of BeautifulSoup class containing an
    XML-tree of content.xml file
    journal_info: reference to global dictionary to add title information

    Returns: None. Changes by reference a global dictionary of journal
    information.

    Raises: TODO

    """
    style_name_ru = 'СтатьяНазваниеРус'
    style_name_en = 'СтатьяНазваниеАнгл'

    # Correcting Russian part of XML-tree to fit the desired standard
    correct_tree(content, style_name_ru, 'text:h')

    article_names_list = content.find_all(
        'text:h', {'text:style-name': style_name_ru})

    article_names_ru = []

    # Fill the list of Russian article names
    for article_name in article_names_list:
        article_names_ru.append(clear_text(article_name.get_text()))

    # Correcting English part of XML-tree to fit the desired standard
    correct_tree(content, style_name_en, 'text:h')

    article_names_list = content.find_all(
        'text:h', {'text:style-name': style_name_en})

    article_names_en = []

    # Fill the list of English article names
    for article_name in article_names_list:
        article_names_en.append(clear_text(article_name.get_text()))

    # Creating key ARTICLES in global dictionary of journal information
    if 'ARTICLES' not in journal_info:
        journal_info['ARTICLES'] = {}

    for i, item in enumerate(article_names_ru, 1):

        article_names_dict = dict(
            {"ARTICLE_NAME_UPPERCASE_RU": item,
             "ARTICLE_NAME_UPPERCASE_EN": article_names_en[i-1]})

        if i not in journal_info['ARTICLES']:
            journal_info['ARTICLES'][i] = {}

        journal_info['ARTICLES'][i] = article_names_dict


def get_article_rubric(odt_content, journal_info):

    style_name_ru = 'СтатьяРубрикаРус'
    style_name_en = 'СтатьяРубрикаАнгл'

    correct_tree(odt_content, style_name_ru, 'text:p')
    correct_tree(odt_content, style_name_en, 'text:p')

    rubric_names_ru_list = odt_content.find_all(
        'text:p', {'text:style-name': style_name_ru})

    rubric_names_en_list = odt_content.find_all(
        'text:p', {'text:style-name': style_name_en})

    # Creating key ARTICLES in global dictionary of journal information if
    # not exist
    if 'ARTICLES' not in journal_info:
        journal_info['ARTICLES'] = {}

    for i, rubric in enumerate(rubric_names_ru_list, 1):
        if i not in journal_info['ARTICLES']:
            journal_info['ARTICLES'][i] = {}
        journal_info['ARTICLES'][i]['RUBRIC_NAME_RU'] = rubric.get_text()

    for i, rubric in enumerate(rubric_names_en_list, 1):
        journal_info['ARTICLES'][i]['RUBRIC_NAME_EN'] = rubric.get_text()


def get_article_keywords(odt_content, journal_info):

    style_name_ru = 'СтатьяИнфоРус'
    style_name_en = 'СтатьяИнфоАнгл'

    correct_tree(odt_content, style_name_ru, 'text:p')
    correct_tree(odt_content, style_name_en, 'text:p')

    info_ru_list = odt_content.find_all(
        'text:p', {'text:style-name': style_name_ru})

    info_en_list = odt_content.find_all(
        'text:p', {'text:style-name': style_name_en})

    keywords_ru_list = []
    keywords_en_list = []

    for element in info_ru_list:
        if 'Ключевые слова:' in (element.get_text()):
            element_string = element.get_text()
            cleared_string = element_string.replace('Ключевые слова: ', '')
            keywords_ru_list.append(cleared_string)

    for element in info_en_list:
        if 'Keywords:' in (element.get_text()):
            element_string = element.get_text()
            cleared_string = element_string.replace('Keywords: ', '')
            keywords_en_list.append(cleared_string)

    # Creating key ARTICLES in global dictionary of journal information if
    # not exist
    if 'ARTICLES' not in journal_info:
        journal_info['ARTICLES'] = {}

    for i, item in enumerate(keywords_ru_list, 1):
        if i not in journal_info['ARTICLES']:
            journal_info['ARTICLES'][i] = {}
        journal_info['ARTICLES'][i]['KEYWORDS_RU'] = clear_text(item)

    for i, item in enumerate(keywords_en_list, 1):
        journal_info['ARTICLES'][i]['KEYWORDS_EN'] = clear_text(item)


def get_info_from_citation_par(odt_content, journal_info):
    """Gets English and Russian information from citation paragraph.

    Gets English and Russian information from citation paragraph:
    - Article name in sentence case (Example: Оптимизация управления
    банковскими активами на основе процессного подхода)
    - Article names (Example: Заернюк В.М., Снитко Н.О.)
    - DOI (Example: https://doi.org/10.24891/fa.11.2.223)

    Args: odt_content: an instance of BeautifulSoup class containing an
    XML-tree of content.xml file
    journal_info: reference to global dictionary to add title information

    Returns: None. Changes by reference a global dictionary of journal
    information.

    Raises: TODO
    """

    i = 1

    ru_regex = r'^Для цитирования:\s(.*?[А-ЯЁ]\.)[\s]+(.*)[\s]+//[\s]+'
    r'?([а-яёА-ЯЁ\s:,]+).*([2][0][1-9][0-9]).*Т\.[\s]+?([\d][\d]),[\s]+?№\s'
    r'?(\d\d?)\..*С\.?[\s]+?([\d\s–-]+)'

    regex_ru_citation = re.compile(ru_regex)

    regex_en_citation = re.compile(
        r'^Please cite this article as:(.*[A-Z][a-z]?\.\s)(.*?(?=Finance and'
        ' Credit|Economic Analysis: Theory and Practice|Regional Economics:'
        ' Theory and Practice|National Interests: Priorities and Security|'
        'Financial Analytics: Science and Experience|International'
        ' Accounting|Digest Finance))')

    publication_year = 0
    journal_volume = 0
    issue_number = 0

    for element in odt_content.find_all('text:p'):

        if 'Для цитирования' in element.get_text():

            result = regex_ru_citation.match(clear_text(element.get_text()))
            print(result[2])
            (journal_info['ARTICLES'][i]
             ['ARTICLE_NAME_SENTENCE_CASE_RU']) = clear_text(result[2])

            journal_info['ARTICLES'][i]['AUTHORS_RU'] = clear_text(result[1])

            # result[3]) Journal name

            if publication_year == 0:
                publication_year = result[4]  # Publication year

            if journal_volume == 0:
                journal_volume = result[5]  # Journal volume

            if issue_number == 0:
                issue_number = result[6]  # Issue number

            journal_info['ARTICLES'][i]['PAGES'] = result[7]
            print(journal_info['ARTICLES'][i]['PAGES'])

            doi_element = element.next_sibling.get_text()

            journal_info['ARTICLES'][i]['DOI'] = doi_element

        if 'Please cite this article as' in element.get_text():

            result = regex_en_citation.match(clear_text(element.get_text()))

            journal_info['ARTICLES'][i]['ARTICLE_NAME_SENTENCE_CASE_EN'] = (
                    clear_text(result[2]).rstrip('.'))

            journal_info['ARTICLES'][i]['AUTHORS_EN'] = clear_text(result[1])

            i += 1

        if 'JOURNAL' not in journal_info:
            journal_info['JOURNAL'] = {}

        journal_info['JOURNAL']['PUBLICATION_YEAR'] = publication_year
        journal_info['JOURNAL']['JOURNAL_VOLUME'] = journal_volume
        journal_info['JOURNAL']['ISSUE_NUMBER'] = issue_number


def get_article_abstract_html(odt_content, journal_info):
    """Gets Russian abstract in HTML form.

    Gets Russian abstract from content.xml using BeautifulSoup.

    Args: odt_content: an instance of BeautifulSoup class containing an
    XML-tree of content.xml file
    journal_info: reference to global dictionary to add title information

    Returns: None. Changes by reference a global dictionary of journal
    information.

    Raises: TODO
    """
    p_tags = odt_content.find_all('text:p')
    abstracts_list = []  # List of all abstract of issue
    for p_tag in p_tags:
        if 'Аннотация' in p_tag.get_text():
            abstract = ''  # Final string for joined paragraphs
            abstract_paragraphs = []  # List of all paragraphs of abstract
            for sibling in p_tag.next_siblings:  # Collect all paragraphs to
                # list (All paragraphs of same level in table)
                paragraph_text = sibling.get_text()

                if ('Издательский дом ФИНАНСЫ и КРЕДИТ' not in
                        paragraph_text and paragraph_text != ''):
                    # Why 'and', not 'or' but it works!?
                    abstract_paragraphs.append('<p>')  # Add HTML tags
                    abstract_paragraphs.append(clear_text(paragraph_text))
                    abstract_paragraphs.append('</p>\n')

            abstracts_list.append(abstract.join(abstract_paragraphs))

    for i, item in enumerate(abstracts_list, 1):  # Populate journal_info
        # dictionary with found abstracts
        journal_info['ARTICLES'][i]['ABSTRACT_HTML_RU'] = item


def get_journal_id(journal_name_ru):

    journal_ids_dict = {'Финансы и кредит': 'fc',
                        'Экономический анализ: теория и практика': 'ea',
                        'Региональная экономика: теория и практика': 're',
                        'Национальные интересы: приоритеты и '
                        'безопасность': 'ni',
                        'Финансовая аналитика: проблемы и решения': 'fa',
                        'Международный бухгалтерский учет': 'ia'}
    return(journal_ids_dict[journal_name_ru])


def get_article_good_id(journal_info, article_number):

    journal_id = get_journal_id(journal_info['JOURNAL']['JOURNAL_NAME_RU'])
    issue_number = journal_info['JOURNAL']['ISSUE_NUMBER']
    print(issue_number)
    page_range = journal_info['ARTICLES'][article_number]['PAGES']
    print(page_range)
    publication_year = journal_info['JOURNAL']['PUBLICATION_YEAR']

    pages_list = page_range.split()
    first_page = pages_list[0]

    delimiter = '-'
    return(delimiter.join([journal_id.upper(), issue_number.zfill(2),
                           publication_year, first_page]))


def get_month_name_of_issue(journal_info):

    issue_number = journal_info['JOURNAL']['ISSUE_NUMBER']
    journal_name = journal_info['JOURNAL']['JOURNAL_NAME_RU']

    quarterly_journals = ['Финансовая аналитика: проблемы и решения']

    month_names_dict = {}

    if (journal_name not in quarterly_journals):
        month_names_dict = {1: 'январь',
                            2: 'февраль',
                            3: 'март',
                            4: 'апрель',
                            5: 'май',
                            6: 'июнь',
                            7: 'июль',
                            8: 'август',
                            9: 'сентябрь',
                            10: 'октябрь',
                            11: 'ноябрь',
                            12: 'декабрь'}
    else:
        month_names_dict = {1: 'февраль',
                            2: 'май',
                            3: 'август',
                            4: 'ноябрь'}

    month_name = month_names_dict[int(issue_number)]

    return(month_name)


def create_journal_abstract_text(journal_info):

    abstract = '<h2>СОДЕРЖАНИЕ</h2>'
    prev_rubric_name = 0
    for i in range(len(journal_info['ARTICLES'])):
        i += 1
        article_name = (journal_info['ARTICLES'][i]
                        ['ARTICLE_NAME_SENTENCE_CASE_RU'])
        rubric_name = (journal_info['ARTICLES'][i]
                       ['RUBRIC_NAME_RU'])

        author_names = (journal_info['ARTICLES'][i]
                        ['AUTHORS_RU'])
        if (rubric_name != prev_rubric_name) or (prev_rubric_name == 0):
            abstract += '<p><strong>{0}</strong></p>\n'.format(
                rubric_name.upper())
        abstract += '<p><em>{0}</em> {1}</p>\n'.format(
            author_names, article_name)

        prev_rubric_name = rubric_name

    return abstract


def create_abstract_text(journal_name, issue_year, issue_volume, issue_number,
                         article_pages, article_authors, article_rubric,
                         article_abstract, article_keywords):
    abstract = ''
    abstract += '<p><strong>Статья опубликована в журнале: </strong> {0}, \
{1}, Т.&nbsp;{2}, №&nbsp;{3}, С.&nbsp;{4}</p>\n'.format(journal_name,
                        issue_year, issue_volume, issue_number, article_pages)
    abstract += '<p><strong>Автор(ы):</strong> {0}</p>\n'.format(
        article_authors)
    abstract += '<p><strong>Рубрика:</strong> {0}</p>\n'.format(article_rubric)
    abstract += '<p><strong>Аннотация</strong></p>\n'
    abstract += '{0}'.format(article_abstract)
    abstract += '<p><strong>Ключевые слова:</strong> {0}\n'.format(
        article_keywords)

    return abstract


def flatten_journal_info_dict(journal_info):

    journal_info_flatted = []

    journal_info_flatted.append(['Название товара',
                                 'Название товара в URL',
                                 'Полное описание',
                                 'Видимость на витрине',
                                 'Применять скидки',
                                 'Размещение на сайте',
                                 'Валюта склада',
                                 'НДС',
                                 'Единица измерения',
                                 'Артикул',
                                 'Цена продажи',
                                 'Параметр: Категория Яндекс Маркета',
                                 'Параметр: Тип публикации',
                                 'Параметр: Формат',
                                 'Параметр: Журнал',
                                 'Параметр: Год публикации',
                                 'Параметр: Месяц публикации'])

    for i in range(len(journal_info['ARTICLES'])):
        j = i + 1
        article = []

        issue_month_name = get_month_name_of_issue(journal_info)
        site_structure_location = (journal_info['JOURNAL']['JOURNAL_NAME_RU'])
        publication_type = 'Статья'
        file_type = 'PDF'
        unit_of_measurement = 'шт'
        # journal_id = get_journal_id(journal_info['JOURNAL']
        # ['JOURNAL_NAME_RU'])
        article_good_id = get_article_good_id(journal_info, j)

        abstract_text = create_abstract_text(
            journal_info['JOURNAL']['JOURNAL_NAME_RU'],
            journal_info['JOURNAL']['PUBLICATION_YEAR'],
            journal_info['JOURNAL']['JOURNAL_VOLUME'],
            journal_info['JOURNAL']['ISSUE_NUMBER'],
            journal_info['ARTICLES'][j]['PAGES'],
            journal_info['ARTICLES'][j]['AUTHORS_RU'],
            journal_info['ARTICLES'][j]['RUBRIC_NAME_RU'],
            journal_info['ARTICLES'][j]['ABSTRACT_HTML_RU'],
            journal_info['ARTICLES'][j]['KEYWORDS_RU'])

        translated_article_name = unidecode(journal_info['ARTICLES'][j]
                                            ['ARTICLE_NAME_SENTENCE_CASE_RU'].
                                            lower().replace(' ', '-'))

        translated_article_name = re.sub(r'[\'\:\"\)\(\\\№]', '',
                                         translated_article_name)

        article_price = '300,0'
        visibility = 'выставлен'
        enable_discount = 'да'
        currency = 'RUR'
        vat = 'Без НДС'
        yandex_market_name = 'Все товары/Досуг и развлечения/Книги/\
Журналы и газеты/Наука и образование'

        article.append(journal_info['ARTICLES'][j]
                       ['ARTICLE_NAME_SENTENCE_CASE_RU'])
        article.append(translated_article_name)
        article.append(abstract_text)
        article.append(visibility)
        article.append(enable_discount)
        article.append(site_structure_location)
        article.append(currency)
        article.append(vat)
        article.append(unit_of_measurement)
        article.append(article_good_id)
        article.append(article_price)
        article.append(yandex_market_name)
        article.append(publication_type)
        article.append(file_type)
        article.append(journal_info['JOURNAL']['JOURNAL_NAME_RU'])
        article.append(journal_info['JOURNAL']['PUBLICATION_YEAR'])
        article.append(issue_month_name)

        # article.append(journal_info['JOURNAL']['JOURNAL_VOLUME'])
        # article.append(journal_info['JOURNAL']['ISSUE_NUMBER'])
        # article.append(journal_info['ARTICLES'][j]['AUTHORS_RU'])
        # article.append(journal_info['ARTICLES'][j]['PAGES'])
        # article.append(journal_info['ARTICLES'][j]['DOI'])
        # article.append(journal_info['ARTICLES'][j]['RUBRIC_NAME_RU'])
        # article.append(journal_info['ARTICLES'][j]['KEYWORDS_RU'])
        # article.append(journal_id)

        journal_info_flatted.append(article)

    # Creating journal item at last

    publication_year = journal_info['JOURNAL']['PUBLICATION_YEAR']

    article = []

    issue_month_name = get_month_name_of_issue(journal_info)
    site_structure_location = (journal_info['JOURNAL']['JOURNAL_NAME_RU'])
    publication_type = 'Номер журнала'
    file_type = 'PDF'
    unit_of_measurement = 'шт'
    article_good_id = '###'
    abstract_text = create_journal_abstract_text(journal_info)
    translated_article_name = 'journal_issue'
    article_price = '3000,0'
    visibility = 'выставлен'
    enable_discount = 'да'
    currency = 'RUR'
    vat = 'Без НДС'
    yandex_market_name = 'Все товары/Досуг и развлечения/Книги/\
Журналы и газеты/Наука и образование'

    journal_name_ru = journal_info['JOURNAL']['JOURNAL_NAME_RU']

    article.append('«{0}», {1} {2}'.format(
        journal_name_ru, issue_month_name, publication_year))
    article.append(translated_article_name)
    article.append(abstract_text)
    article.append(visibility)
    article.append(enable_discount)
    article.append(site_structure_location)
    article.append(currency)
    article.append(vat)
    article.append(unit_of_measurement)
    article.append(article_good_id)
    article.append(article_price)
    article.append(yandex_market_name)
    article.append(publication_type)
    article.append(file_type)
    article.append(journal_name_ru)
    article.append(publication_year)
    article.append(issue_month_name)

    journal_info_flatted.append(article)

    return(journal_info_flatted)


def process_journal_info(file_name):

    file = OdtFile(file_name)

    odt_content = BeautifulSoup(file.get_content_file_unicode(), 'lxml-xml')

    # odt_styles = BeautifulSoup(file.get_styles_file_unicode(), 'lxml-xml')

    journal_info = {}  # Global dictionary of journal data

    get_journal_through_issue_number(odt_content, journal_info)
    get_journal_titles(odt_content, journal_info)
    get_article_names_from_title(odt_content, journal_info)
    get_info_from_citation_par(odt_content, journal_info)
    get_article_abstract_html(odt_content, journal_info)
    get_article_rubric(odt_content, journal_info)
    get_article_keywords(odt_content, journal_info)

    return(journal_info)


def dump_exist(obj_name):

    my_file = Path(obj_name + '.pkl')

    if my_file.is_file():
        return True
    else:
        return False


def save_obj(obj, name):
    with open(name + '.pkl', 'wb') as f:
        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)


def load_obj(name):
    with open(name + '.pkl', 'rb') as f:
        return pickle.load(f)


obj_name = 'journal_info'

if dump_exist(obj_name):
    journal_info = load_obj(obj_name)
else:
    journal_info = process_journal_info('./test_file/EA-2018-11.odt')
    save_obj(journal_info, obj_name)


flattened_journal_info = flatten_journal_info_dict(journal_info)
